{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name: Eric Lindgren\n",
    "#### CID: ericlin\n",
    "#### PSN: 970222-1954"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-squared hypothesis testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mi i s our prior for probability pi; since we assume it constant, we take m to be uniform => mi = 1/100.\n",
    "mi = 1/100\n",
    "# M is the total number of outcomes\n",
    "M = 100\n",
    "# average result\n",
    "avg_res = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the method of maximum entropy. Using Lagrange multipliers, the parameter $\\lambda_1$ that maximizes the entropy $S$ can be found through: \n",
    "\n",
    "$$ dS - \\lambda C_0 - \\lambda_1 C_1, \\hspace{10px} S = - \\sum_i p_i \\ln{\\frac{p_i}{m_i}} \\rightarrow$$\n",
    "$$ d\\left[- \\sum_i p_i \\ln{\\frac{p_i}{m_i}} - \\lambda \\left(\\sum_i p_i - 1\\right) - \\lambda_1 \\left(\\sum_i i p_i - 10\\right)   \\right] = 0.$$\n",
    "\n",
    "We have the freedom to choose $\\lambda$ such that one of these terms is 0. Then, for each of the other terms, we require: \n",
    "\n",
    "$$-\\ln{p_i/m_i} - 1 (should be m_i!) - \\lambda - \\lambda_i i = 0\\rightarrow  p_i = m_i e^{-(1+\\lambda)} e^{-\\lambda_1 i}$$\n",
    "\n",
    "We have two conditions: \n",
    "\n",
    "$$ 1) \\hspace{10px} \\sum_i p_i = 1 = e^{-(1+\\lambda)} \\sum_i m_i e^{-\\lambda_1 i}\\rightarrow e^{-(1+\\lambda)} = \\frac{1}{\\sum_i^M m_i e^{-\\lambda_1 i}}, $$\n",
    "$$ 2) \\hspace{10px} \\sum_i i p_i = 10 = e^{-(1+\\lambda)} \\sum_i i m_i e^{-\\lambda_1 i}  $$\n",
    "Where $i$ is both the index and the value of the die for outcome $i$. This gives us:\n",
    "\n",
    "$$ 10 = \\frac{\\sum_j^M j m_j e^{-\\lambda_1 j}}{\\sum_i^M m_i e^{-\\lambda_1 i}}.$$\n",
    "\n",
    "Also, utilize that $m_i = m_j = $ constant. Thus, our final expression for the $\\lambda_1$ which maximizes our entropy is given by solving: \n",
    "\n",
    "$$ 10 = \\frac{\\sum_j^M je^{-\\lambda_1 j}}{\\sum_i^M e^{-\\lambda_1 i}} \\rightarrow \\sum_j^M je^{-\\lambda_1 j} - 10 \\sum_i^M e^{-\\lambda_1 i} = 0.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max entropy equation passing unit test: True\n"
     ]
    }
   ],
   "source": [
    "def max_ent_equation(lambda_1, target, M):\n",
    "    '''\n",
    "    Returns the difference between the value of the final equation for lambda_1 and it's target. \n",
    "    Here, the target is target = 10, and M = 100 (the number of discrete outcomes).\n",
    "    '''\n",
    "    sum_1 = np.sum([j*np.exp(-lambda_1*j) for j in range(1,M+1)])  # M points between 1 and 100\n",
    "    sum_2 = np.sum([np.exp(-lambda_1*i) for i in range(1,M+1)])\n",
    "    return sum_1-target*sum_2\n",
    "\n",
    "# Test\n",
    "print(f'Max entropy equation passing unit test: {-0.368==np.round((max_ent_equation(1,2,2)),3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The solution for lambda_1 is lambda_1 = 0.11.\n"
     ]
    }
   ],
   "source": [
    "# Use scipy.optimize.fsolve to solve this equation - fsolve finds the zero point\n",
    "lambda_1 = opt.fsolve(func=max_ent_equation, x0=-1, args=(avg_res, M))\n",
    "lambda_1 = lambda_1[0]\n",
    "print(f'The solution for lambda_1 is lambda_1 = {(lambda_1):.2f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this lambda 1 to evaluate $$e^{-(1+\\lambda)} = \\frac{1}{\\sum_i^M m_i e^{-\\lambda_1 i}}.$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e^(-(1+lambda)) passes unit tests: True\n"
     ]
    }
   ],
   "source": [
    "def e_power_lambda(lambda_1, mi, M):\n",
    "    return 1/(np.sum([mi*np.exp(-lambda_1*i) for i in range(1,M+1)]))\n",
    "\n",
    "# Test\n",
    "print(f'e^(-(1+lambda)) passes unit tests: {0.994==np.round((e_power_lambda(1,2,2)),3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'e_power_lambda' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-b3194f3729bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0me_pow_lambda\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me_power_lambda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlambda_1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Now, finally, calculate our probabilities p_i and make a bar plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mp_i_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0me_pow_lambda\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlambda_1\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mi_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'e_power_lambda' is not defined"
     ]
    }
   ],
   "source": [
    "e_pow_lambda=e_power_lambda(lambda_1,mi,1)\n",
    "\n",
    "# Now, finally, calculate our probabilities p_i and make a bar plot\n",
    "p_i_s = np.array([mi * e_pow_lambda * np.exp(-lambda_1*i) for i in range(1,M+1)])\n",
    "i_s = np.array([i for i in range(1,M+1)])\n",
    "\n",
    "# Sanity check - our sum of p_i_s should be 1\n",
    "#assert 1 == p_i_s.sum(), \"p_i_s does not sum to 1!\"\n",
    "\n",
    "# Plot\n",
    "# Set plot params\n",
    "plt.rc('font', size=14)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=14)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=16)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=14)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=14)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=14)    # legend fontsize\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "ax.bar(i_s, p_i_s, 1, label=\"p_i\")  # TODO make bar plot\n",
    "ax.set_xlabel(\"i, value of die\")\n",
    "ax.set_ylabel(\"p_i\")\n",
    "ax.set_title(\"Bar plot of p_i for 100 sided die\")\n",
    "\n",
    "# Generate an exponential fit, and plot that one as well:\n",
    "# p_i_s ~ Ae^(Bi) => ln(p_i_s) = ln(A) + Bi\n",
    "A_B = np.polyfit(i_s, np.log(p_i_s), 1)\n",
    "A = np.exp(A_B[1])\n",
    "B = A_B[0]\n",
    "\n",
    "ax.plot(i_s,A*np.exp(B*i_s), 'r', linewidth=2, label=\"Exponential fit\")\n",
    "\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
