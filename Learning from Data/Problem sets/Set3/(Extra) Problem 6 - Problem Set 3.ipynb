{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name: Eric Lindgren\n",
    "#### CID: ericlin\n",
    "#### PSN: 970222-1954"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: (n_data, pixel_width, pixel_height) = (1797, 8, 8)\n",
      "                       with labels (n_data) = (1797,)\n",
      "\n",
      "flattened input, X: (n_inputs, n_features)  = (1797, 64)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import \n",
    "from sklearn import datasets\n",
    "\n",
    "# ensure the same random numbers appear every time\n",
    "np.random.seed(0)\n",
    "\n",
    "# download MNIST dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# define inputs and labels\n",
    "inputs = digits.images\n",
    "labels = digits.target\n",
    "\n",
    "print(f\"inputs: (n_data, pixel_width, pixel_height) = {inputs.shape}\")\n",
    "print(f\"                       with labels (n_data) = {labels.shape}\")\n",
    "\n",
    "\n",
    "# flatten the image\n",
    "# the value -1 means dimension is inferred from the remaining dimensions: 8x8 = 64\n",
    "n_inputs = len(inputs)\n",
    "inputs = inputs.reshape(n_inputs, -1)\n",
    "print(f\"\\nflattened input, X: (n_inputs, n_features)  = {inputs.shape}\")\n",
    "\n",
    "\n",
    "# choose some random images to display\n",
    "indices = np.arange(n_inputs)\n",
    "random_indices = np.random.choice(indices, size=5)\n",
    "\n",
    "for i, image in enumerate(digits.images[random_indices]):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title(f\"Label: {digits.target[random_indices[i]]:1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images: 1257\n",
      "Number of test images:      540\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ensure the same random numbers appear every time\n",
    "np.random.seed(0)\n",
    "\n",
    "train_size = 0.7\n",
    "test_size = 1 - train_size\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(inputs, labels, train_size=train_size,\n",
    "                                                    test_size=test_size)\n",
    "\n",
    "print(f\"Number of training images: {len(X_train):4}\")\n",
    "print(f\"Number of test images:     {len(X_test):4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to categorical turns our integer vector into a onehot representation\n",
    "# we implement it in in numpy\n",
    "def to_categorical_numpy(integer_vector):\n",
    "    n_inputs = len(integer_vector)\n",
    "    n_categories = np.max(integer_vector) + 1\n",
    "    onehot_vector = np.zeros((n_inputs, n_categories))\n",
    "    onehot_vector[range(n_inputs), integer_vector] = 1\n",
    "    \n",
    "    return onehot_vector\n",
    "\n",
    "Y_train_onehot, Y_test_onehot = to_categorical_numpy(Y_train), to_categorical_numpy(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Full object oriented implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(\n",
    "            self,\n",
    "            X_data,\n",
    "            Y_data,\n",
    "            n_hidden_neurons=50,\n",
    "            n_categories=10,\n",
    "            epochs=10,\n",
    "            batch_size=100,\n",
    "            eta=0.1,\n",
    "            lmbd=0.0):\n",
    "\n",
    "        self.X_data_full = X_data\n",
    "        self.Y_data_full = Y_data\n",
    "\n",
    "        self.n_inputs = X_data.shape[0]\n",
    "        self.n_features = X_data.shape[1]\n",
    "        self.n_hidden_neurons = n_hidden_neurons\n",
    "        self.n_categories = n_categories\n",
    "\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.iterations = self.n_inputs // self.batch_size\n",
    "        self.eta = eta\n",
    "        self.lmbd = lmbd\n",
    "\n",
    "        self.create_biases_and_weights()\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1./(1. + np.exp(-z))\n",
    "\n",
    "    def create_biases_and_weights(self):\n",
    "        self.hidden_weights = np.random.randn(self.n_features, self.n_hidden_neurons)\n",
    "        self.hidden_bias = np.zeros(self.n_hidden_neurons) + 0.01\n",
    "\n",
    "        self.output_weights = np.random.randn(self.n_hidden_neurons, self.n_categories)\n",
    "        self.output_bias = np.zeros(self.n_categories) + 0.01\n",
    "\n",
    "    def feed_forward(self):\n",
    "        # feed-forward for training\n",
    "        # Hidden layer\n",
    "        self.z_h = np.matmul(self.X_data_full, self.hidden_weights)  # z_h\n",
    "        self.a_h = sigmoid(z=self.z_h)  # a_h\n",
    "        # Output layer\n",
    "        self.z_o = np.matmul(self.a_h, self.output_weights)\n",
    "        raise NotImplementedError(\"The feed_forward method is not yet implemented.\")\n",
    "\n",
    "    def backpropagation(self):\n",
    "        raise NotImplementedError(\"The backpropagation method does not yet include the regularizer.\")\n",
    "        \n",
    "        error_output = self.probabilities - self.Y_data\n",
    "        error_hidden = np.matmul(error_output, self.output_weights.T) * self.a_h * (1 - self.a_h)\n",
    "\n",
    "        self.output_weights_gradient = np.matmul(self.a_h.T, error_output)\n",
    "        self.output_bias_gradient = np.sum(error_output, axis=0)\n",
    "\n",
    "        self.hidden_weights_gradient = np.matmul(self.X_data.T, error_hidden)\n",
    "        self.hidden_bias_gradient = np.sum(error_hidden, axis=0)\n",
    "\n",
    "        # Add the weight gradients from the regularizer term.\n",
    "        # Add code here\n",
    "\n",
    "        self.output_weights -= self.eta * self.output_weights_gradient\n",
    "        self.output_bias -= self.eta * self.output_bias_gradient\n",
    "        self.hidden_weights -= self.eta * self.hidden_weights_gradient\n",
    "        self.hidden_bias -= self.eta * self.hidden_bias_gradient\n",
    "\n",
    "    def predict(self, X):\n",
    "        raise NotImplementedError(\"The predict method is not yet implemented.\")\n",
    "\n",
    "    def predict_probabilities(self, X):\n",
    "        raise NotImplementedError(\"The predict_probabilities method is not yet implemented.\")\n",
    "\n",
    "    def train(self):\n",
    "        data_indices = np.arange(self.n_inputs)\n",
    "\n",
    "        for i in range(self.epochs):\n",
    "            for j in range(self.iterations):\n",
    "                # pick datapoints with replacement\n",
    "                chosen_datapoints = np.random.choice(\n",
    "                    data_indices, size=self.batch_size, replace=False\n",
    "                )\n",
    "\n",
    "                # minibatch training data\n",
    "                self.X_data = self.X_data_full[chosen_datapoints]\n",
    "                self.Y_data = self.Y_data_full[chosen_datapoints]\n",
    "\n",
    "                self.feed_forward()\n",
    "                self.backpropagation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
